# 20190325 一晩でKubernetesを覚えて帰ろう。ワンナイトBootCamp!

## イントロダクション

- k8sって何
  - コンテナオーケストレーションしてくる
  - コンテナ
    - 仮想マシンの一種
  - コンテナ運用が始まったことで明らかになった課題
    - リソースの空きがあるホストを洗濯してコンテナをデプロイ
    - コンテナ同士の連携を管理
  - コンテナオーケストレーションが実現すること
    - 複数のリソースを大きなリソースとして見せてくれる
    - コンテナをデプロイするとどこのリソース上にできているかはユーザは意識する必要がない
    - 負荷分散する際に空いているリソースを選択して水平スケーリングしてくれる
  - k8sは他のと何が違うの
    - Apache のやつとか
    - dokcerんちゃらがある
    - 様々なOSSと組み合わせて柔軟に機能拡張が可能であることが上記のコンテナオーケストレーションツールと異なる
    - 本格的な宣言的オペレーションとinfrastratucure as Codeを実現可能

## k8sの基礎

- R&Dの組織でk8sの運用は向いている

- K8sの全体像
  - infrastructurer components
    - Master
      k8sを管理するコンポーネントが配置されるサーバー群
    - node
    - etcd cluster
      - 高信頼性Kvs
  - master
    - Api SErver
      - etcdへのwrite redを行うAPIサーバ
      - 複数台配置して冗長化構成を取ることがdきえる
    - Controller Manager
      - デプロイするコンテナの個数などを管理する
      - 複数台配置できるはリーダーは１つだけ
    - Scheduler
      - コンテナをどのNodeにデプロイするか
  - Node
    - Container runtime
      - Docker以外も使用できる
    - Kubelet
      - Node上に配置されるエージェント。コンテナの起動/停止などを行う
    - Kube-proxy
      - コンテントの接続を保証するためにNodeのネットワークを管理する
    - MasterとControl Plane componentsの違い
      - Master
        - API Server / Controller Manager / Scheduler
      - Control Plane components
        - API Server / Controller Manager / Scheduler / kubelet/ kube-proxy
  - kubectl
    - ユーザがk8sを操作する際に使うコマンド
    - etcdの信頼性が低いとk8sのコントロールが正しく行われない可能性がある

- 構成要素の全体像
  - workloadの一覧
    - pod
      - コンテナのデプロイの最小単位
      - １個のPodに複数のコンテナを定義できる(SideCar)
      - 定義された複数のコンテナは必ず同一のIPアドレスになる
        - Podの単位にNICが１つある
        - SideCarがあると何が嬉しいのか
          - アプリケーションに対する監視やログの収集などを行うために便利
          - SideCarとして登録したコンテナが１つ死ぬとPod全体が死ぬ
    - RelicaSet
      - デプロイしたPod数を維持するリソース
      - 指定されたPod数を維持する、減ったら増やし、増えたら減らす
      - IPアドレスを利用した通信はコンテナ内ではおこなえない。
        - 通信はラベル指定で行う
        - label Namgeが重複すると死亡するので正しく管理/定義する必要がある。(*重要なポイント)
      - Deplyment(deploy)
        - RollingUpdateするためにReplicaSetを管理するリソース
        - DeploymentがReplicaSetを作り、Podを作る
          - v1のreplicazsetとpodを作る
          - v2をリリースする
          - v2のreplicasetを作る
          - v1のreplicasetを1つ減らしてく
            - podがへる
          - v2の
    - Configuration
      - ConfigMap(* 要確認)
        - 設定情報をkey-valueの形式で保持するリソース
        - 環境ごとの設定を保持する
        - Manifestを書く
        - 環境変数とする
        - Volumeとしてマウントする
      - Secret
        - 機密情報を保持するリソース
        - opaque
          - 一般的
          - Key-valueで機密情報を保持し扱い方はConfigmapと同じ
          - Configmapとの違い
            - 値がBASE64エンコードされる
            - /tmpに置かれる
          - 使い方
            - sercretに対して特定のユーザを除きGet. Listの権限を与えない
            - Configmapとは別の場所で管理する
    - Discovery & LBの一覧
      - ClusterIP
        - クラスタ内のアクセスを保証する
        - クラスタ内のPodへのアクセスをLBする
        - Service名で名前解決してクラスタ内のPodへアクセスする
        - ClusterIPはどこにできるの？
      - NodePort
        - クラスタ外からクラスタのPortを指定してアクセスする
        - クラスタの全てのNode指定のPortへのアクセスをPodへ保証する
        - Ingress が外部LBからクラスタ内のコンテナへの通信をサポートしてくれる（IngressはCNCDプロジェクトのOSS)
        - PodとServiceのNWが別
    - Namespace
      - １つのクラスタの中を下層のクラスタで分けることができる
      - 使い方
        - 商用、検証、開発環境で２つのクラスタの中でわける
        - 開発チーム単位で分ける
    - Manifestを中心にしたオペレーション
      - コマンドでも管理できるか状態が管理できなくなるのでManifestファイル単位での管理が望ましい


## 動いているところを見てみよう

- sepc/type; LoadBalancer
  - 指定するとクラウドプラットフォーム上のLBがプロビショニングされる
  - docker on mac だとどうなるんだろう？
  - typeの指定はクラウドプラットフォームごとに何か特別な指定が存在するのだろうか？
- kubectrl exec コンテナID ${cmnd}
  - コンテナ内のコマンドを叩ける
  - 内部ネットワークの疎通確認とかに利用できる
  - alpine linuxとかだと使えないようね？
    - 最初はubuntuとかを選んで検証し問題なければコンテナイメージをalpine linuxに切り替えるとかすればOK？
- manifest ファイルを変更するのであれば
  - k apply -f ${マニフェストファイルパス}
- LBが必ずしもround-robinとは限らない
  - 状況に応じて変わる

## k8sのアーキテクチャと発展的な使い方

- 本日はversion v1.13.4 の話
- ここの話がベース
  - <https://github.com/jamiehannaford/what-happens-when-k8s>
- kubectl run nginx --image=nginx --replicas=3
  - kubectl run  ≒ docker run
  - 1 resource validate
    - see $kubectl api-resources
  - 2 load api schema
    - look ~/.kube.cache.discovery/
  - 3 generate request
  - 4 look kubeconfig check priority
    - 認証情報を参照する優先順位
      - kubectol --kubeconfig
      - ${KUBECONFIG} kubectl
      - ~/.kube/
  - Auth Journy
    - Authentication
      - kube-apiserver
        - 全てのクラスタの窓口になる
        - 認証方法
          - X509
            - curl -key client,key - cert client.crt -cacert ca,crt
          - bearer
            - curl -H "Authri"
          - basic
            - user:password
    - Authorization
      - 受け取った要求の権限を保持しているかを確認する
      - etcdから受け取る
    - Admission Controll
      - 難しい
      - 認証/認可の後にセキュリティ周りのリクエストを落とす
    - /apps/v1beta2/devployment
      - リソースを登録する？
    - request validation
      - JSON DESELIZE -> Validation Reqeust form
      - key - value の情報となっているかをチェックする
  - etcd
    - databaseのフロントなる
    - httpで通信できる
    - jsonを使って更新できる
    - 分散型のkvs
    - backendにBBOLDってのが存在している
    - etcdを介して要求情報が永続化される
  - ここまでで、nginxのイメージをreplicaset 3で作るってことを認識する
  - controller loop
    - バッチだとおもえ
    - 定期的にポーリングできる
    - kube-controller-manager
      - リソースを管理するやつ
    - controllerはreplicasetのバージョンを管理する?
  - kube scheduller
    - 作るべきpodをk8s上のどこのリソースに作るのかを判断するやつ
    - nodeのリソースをチェックしたりする
  - pod deploy
    - kubelet
      - クラスタリングされている
      - nodeごとにkubeletに作られて各ノードの状態とマスタのetcdの状態が一致しているかをAPIサーバに問い合わせる？
  - pod deploy
    - volumes
      - 領域の確保
    - base pause image
      - ベースイメージをpullしてくる
      - Dockerfileのスクラッチなんちゃら
      - ネットワークを先に構築するためにベースイメージを作る
    - network if
      - 開発者側がcalico?とか選択できる
    - running image
