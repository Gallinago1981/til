# JSUG 20181212

## Spring Bootで実装するエンタープライズ統合パターン

- RPC is illusion
  - リモートのプログラムがあたかもローカルで動いているかのように見えることを示している
  - 通信が発生することによる処理遅延の考慮が必要

- 非同期メッセージング
  - デザインパターン
    - デザインランゲージ
  - よく使われるプログラミング構造に名前をつけた
  - Enterprise Integration Pattern
    - 700ページくらいの本
    - Sender -> message -> Channel(Queue) -> Receiver
    - 1 システム全体でメッセージを使ったコミュニケーションが行われる
    - 2 チャネルには論理的なアドレスを付与できる。その論理的なアドレスは場所に依存する
    - 3 メッセージはチャネルに
  - メリット
    - 一時的なシステムの分離
    - 電波による影響を限定的にする
    - スロットリングできる
      - receiverのベースでMessageを処理できる
      - Sendarとreceiverが独立しているのでチューニングすることができる
    - SnedeとReceiverの間でMessagewoルーティングしたりMessageそのものを交換したりできる
    - スルー
    - エラーハンドリングは行なっていない
      - エラーは状態であってその結果をハンドリングしたりはしない
      - だから変更に強くなる
      - 対応方法
        - 何もしない
          - 業務プロセスに影響を及ぼさないのであれば、あとで対応を行うなどを考慮する
          - リトライする
            - エラーになったらなかったことにしてリトライする
          - エラーによる損失を保証する
            - お金を支払って解消する
  - 非同期はシーケンス図で処理を表すのは難しい
  - メッセージングフレームワーク？
    - Apache Camel
    - Spring Integration
    - Apache Mesos

- Spring Integration
  - Core Messaging
    - Sender/ reciever
    - Channel Adapter
      - 色々とあると
        - MongoDB, FTP, SFTP, Kafkaなど
    - Replay Channel
      - レスポンスを受け取るチャネル
    - channel
      - threadなどの非同期処理を指し示す？
      - PollableChannel
      - SubscribableChannel
      - Direct Channel
        - threadlocalの情報を共有する場合
  - Integration Endpoints
    - 外部サービスとの連携
  - Content Enricher
    - MessageのHeader/Footerに付与することができる
  - Message Router
    - messageの内容を確認してどのapplicationを使うかを分別するやつ
  - Splitter
    - messageのpayloadを分割しそれぞれ独立した処理を行うこと
  - Service Activator
    - 外部サービスの結果を受け取りFlowに戻す
  - Aggregator
    - 分割されたメッセージを統合するやつ
    - 制限時間を設けることができる
- Spring Cloud stream is spring tegration on steroids
  - Spring Cloud StreamはMessageアーキテクチャで作られたアプリケーションを数珠つなぎにしたもの
  - Spring Cloud DataFlow で垂直方向のオートスケーリングができる？

## Spring Cloud Dataflowで構成されるIIJ IoTサービス

- Enterprise Integration Patternがどのようにシステム構築、運用されるのか
- IIJ IoT
  - データストレージ
    - データを蓄積する低コストストレージ
  - データハブ
    - センサーデータの外部システムへの転送

- 以前のアーキテクチャと課題
  - 以前はsparkで実装されていた
  - センサー -> Gateway -> Kafka -> Spark App(データハブ)  -> 顧客サーバへ転送 -> 転送結果をRedisに保存
                                -> Spark App(データストレージ) -> 複数のデータを１つに束ねる -> 束ねたデータをファイルとしてアップデート -> アップロード結果をRedisに保存
  - 処理をStreamingにしたい
    - マイクロバッチをやめた
  - 昨日の拡張性・保守性をあげたい
    - 処理を分けたい
    - 機能を追加することでモノシリックなアプリになってしまう
  - スケールが難しい
    - スケールアップをしたい

- Spring Data Flowによる改善アプローチ
  - Messageを単位としたEvent-drivenな処理を実現することに特化したフレームワーク

- Source(Kafka topic) - Processor(HTTP Client) - Sink(RedisClient)
- プロセスを分割したことでイミュータブルなJARを構築することができ保守性が向上した

- Spring Cloud Streamで実装したアプリケーションをどこで動かす
  - Spring Clound Data Flowで対応した
    - GUI, CLIが提供されている
    - コンポーネント間のパイプラインをDSLで表現できる
    - Deployer
      - どこのプラットフォーム上で動いているかを意識しないで使っている

- Instanceで保持したDB情報の更新をどのように行うのか
  - レイテンシーは小さくしたい
  - メモリ上に持っている
  - Spring Clound Config, Spring Clound Netfilix(Eureka), Spring Clound Busを利用してConfigのランタイムアップデートをどのように実現するか
    - Eureka - DNSのようなもの

- スケーラビリティ
  - Spling Clound Data FlowでStreamをデプロイするときに起動数を指定する

- 死活監視について
  - eureka が見ている
  - プラットフォーマーが監視しているのよ
  - k8sのデフォルトのpod監視があるよ

- Spark から Spring Data Flowに変えたことでリソースがあればあるほどパフォーマンスは上がった
- アグリゲータは注意
  - redisが遅い
  - グループを作りredisに書き出して、取り出してというので遅くなった